{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "\n",
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_mBoWuAWDiv",
        "outputId": "4b3fcfdb-629e-441a-a048-bc8b6b3ed363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Using cached openai-0.27.1.tar.gz (57 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCRZTCrgV28C",
        "outputId": "d6e0399b-46f2-49b7-a3ac-7e350a89f570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from google.colab import drive\n",
        "import random\n",
        "#gpt2\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here # read data\n",
        "trump_tweets=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/realdonaldtrump.csv\")\n",
        "trump_tweets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "EgxG9p42WICc",
        "outputId": "5bb7d9aa-e7f1-41d1-ded0-a55541dea6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                               link  \\\n",
              "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
              "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
              "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
              "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
              "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
              "\n",
              "                                             content                 date  \\\n",
              "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
              "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
              "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
              "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
              "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
              "\n",
              "   retweets  favorites mentions hashtags  \n",
              "0       510        917      NaN      NaN  \n",
              "1        34        267      NaN      NaN  \n",
              "2        13         19      NaN      NaN  \n",
              "3        11         26      NaN      NaN  \n",
              "4      1375       1945      NaN      NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ec34a1-efa4-4fda-a757-45586208173d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1698308935</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 13:54:25</td>\n",
              "      <td>510</td>\n",
              "      <td>917</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1701461182</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-04 20:00:10</td>\n",
              "      <td>34</td>\n",
              "      <td>267</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1737479987</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 08:38:08</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1741160716</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 15:40:15</td>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1773561338</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 09:07:28</td>\n",
              "      <td>1375</td>\n",
              "      <td>1945</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ec34a1-efa4-4fda-a757-45586208173d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ec34a1-efa4-4fda-a757-45586208173d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ec34a1-efa4-4fda-a757-45586208173d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_fil =trump_tweets[trump_tweets['isRetweet']=='f']\n",
        "#del trump_tweets\n",
        "\n",
        "tweets = trump_tweets['content'].copy()\n",
        "#tweets =tweets[:30000]\n",
        "tweets.head()\n",
        "print(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtwgurPtWemu",
        "outputId": "5dfb4f53-a6b7-442b-fdad-81c4a8c2600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Be sure to tune in and watch Donald Trump on L...\n",
            "1        Donald Trump will be appearing on The View tom...\n",
            "2        Donald Trump reads Top Ten Financial Tips on L...\n",
            "3        New Blog Post: Celebrity Apprentice Finale and...\n",
            "4        \"My persona will never be that of a wallflower...\n",
            "                               ...                        \n",
            "43347    Joe Biden was a TOTAL FAILURE in Government. H...\n",
            "43348    Will be interviewed on @ seanhannity tonight a...\n",
            "43349                           pic.twitter.com/3lm1spbU8X\n",
            "43350                           pic.twitter.com/vpCE5MadUz\n",
            "43351                           pic.twitter.com/VLlc0BHW41\n",
            "Name: content, Length: 43352, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the Trump tweet corpus\n",
        "#trump_tweets = pd.read_csv('trump_tweets.csv', encoding='utf-8')\n",
        "\n",
        "# Preprocess the tweets by removing URLs, mentions, and hashtags\n",
        "def preprocess_tweet_text(tweet):\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "    # Remove mentions\n",
        "    tweet = re.sub(r\"@\\S+\", \"\", tweet)\n",
        "    # Remove hashtags\n",
        "    tweet = re.sub(r\"#\\S+\", \"\", tweet)\n",
        "    # Remove newline characters\n",
        "    tweet = tweet.replace('\\n', ' ')\n",
        "    # Remove extra spaces\n",
        "    tweet = re.sub(r\"\\s+\", ' ', tweet)\n",
        "    return tweet.strip()\n",
        "\n",
        "\n",
        "#Section 1.2 Cleaning the data:\n",
        "# text cleaning\n",
        "\n",
        "def rm_link(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def rm_punct2(text):\n",
        "    return re.sub(r'[\"\\-]', ' ', text)\n",
        "    \n",
        "def rm_html(text):\n",
        "    return re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "# def space_bt_punct(text):\n",
        "#     pattern = r'([.,!?-])'\n",
        "#     s = re.sub(pattern, r' \\1 ', text)     # add whitespaces between punctuation\n",
        "#     s = re.sub(r'\\s{2,}', ' ', s)        # remove double whitespaces    \n",
        "#     return s\n",
        "\n",
        "def rm_number(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "def rm_whitespaces(text):\n",
        "    return re.sub(r' +', ' ', text)\n",
        "\n",
        "def rm_nonascii(text):\n",
        "    return re.sub(r'[^\\x00-\\x7f]', r'', text)\n",
        "\n",
        "def rm_emoji(text):\n",
        "    emojis = re.compile(\n",
        "        '['\n",
        "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
        "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
        "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
        "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
        "        u'\\U00002702-\\U000027B0'\n",
        "        u'\\U000024C2-\\U0001F251'\n",
        "        ']+',\n",
        "        flags=re.UNICODE\n",
        "    )\n",
        "    return emojis.sub(r'', text)\n",
        "\n",
        "def make_lower(text):\n",
        "  return text.lower()\n",
        "\n",
        "def spell_correction(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
        "\n",
        "def clean_pipeline(text):    \n",
        "    no_link = rm_link(text)\n",
        "    no_punct = rm_punct2(no_link)\n",
        "    \"\"\"\n",
        "    no_html = rm_html(no_link)\n",
        "    no_extra= preprocess_tweet_text(no_html)\n",
        "    #space_punct = space_bt_punct(no_html)\n",
        "    no_punct = rm_punct2(no_extra)\n",
        "    no_number = rm_number(no_punct)\n",
        "    no_whitespaces = rm_whitespaces(no_number)\n",
        "    no_nonasci = rm_nonascii(no_whitespaces)\n",
        "    no_emoji = rm_emoji(no_nonasci)\n",
        "    lower = make_lower(no_emoji)\n",
        "    spell_corrected = spell_correction(lower)\n",
        "    \"\"\"\n",
        "    return no_punct\n",
        "\n",
        "  \n",
        "print(tweets)\n",
        "tweets = tweets.apply(clean_pipeline)\n",
        "tweets=tweets.replace('', np.nan).dropna()\n",
        "tweets.head()\n",
        "print(tweets)\n",
        "tweets.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INs5hiCOtc-_",
        "outputId": "90cbb1a5-13b2-4d91-a91e-3c61b50d7543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Be sure to tune in and watch Donald Trump on L...\n",
            "1        Donald Trump will be appearing on The View tom...\n",
            "2        Donald Trump reads Top Ten Financial Tips on L...\n",
            "3        New Blog Post: Celebrity Apprentice Finale and...\n",
            "4        \"My persona will never be that of a wallflower...\n",
            "                               ...                        \n",
            "43347    Joe Biden was a TOTAL FAILURE in Government. H...\n",
            "43348    Will be interviewed on @ seanhannity tonight a...\n",
            "43349                           pic.twitter.com/3lm1spbU8X\n",
            "43350                           pic.twitter.com/vpCE5MadUz\n",
            "43351                           pic.twitter.com/VLlc0BHW41\n",
            "Name: content, Length: 43352, dtype: object\n",
            "0        Be sure to tune in and watch Donald Trump on L...\n",
            "1        Donald Trump will be appearing on The View tom...\n",
            "2        Donald Trump reads Top Ten Financial Tips on L...\n",
            "3        New Blog Post: Celebrity Apprentice Finale and...\n",
            "4         My persona will never be that of a wallflower...\n",
            "                               ...                        \n",
            "43347    Joe Biden was a TOTAL FAILURE in Government. H...\n",
            "43348    Will be interviewed on @ seanhannity tonight a...\n",
            "43349                           pic.twitter.com/3lm1spbU8X\n",
            "43350                           pic.twitter.com/vpCE5MadUz\n",
            "43351                           pic.twitter.com/VLlc0BHW41\n",
            "Name: content, Length: 43351, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43351"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
        "                                          bos_token='<|sos|>', \n",
        "                                          eos_token='<|eos|>', \n",
        "                                          pad_token='<|pad|>')\n",
        "\n",
        "\n",
        "tokenizer.encode(\"Sample Text\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrd7Fuk0XJru",
        "outputId": "9f5c956d-3712-4b17-cf6f-f5b46ca6e75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36674, 8255]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I added three new tokens in the pre-trained GPT2 tokenizer: \\ <|sos|> : start of sentence \\ <|eos|> : end of sentence \\ <|pad|> : padding token\n",
        "\n"
      ],
      "metadata": {
        "id": "Yr_imbY8Xaog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tweet = min(max([len(tokenizer.encode(tweet)) for tweet in tweets]),100)\n",
        "\n",
        "print(f'The longest tweet is {max_tweet} tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cae_Kv-aXR0w",
        "outputId": "f6c7c81f-9411-4404-d929-bbf790618c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest tweet is 100 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create a custom dataloader for our tweets using torch Dataset. \\ Each entry in the dataset will be two tensors, one which is the encoding for the string and one which is the attention mask\n",
        "\n"
      ],
      "metadata": {
        "id": "B_UsU-e7XWVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self,tweets,tokenizer,gpt2_type=\"gpt2\",max_length=max_tweet):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attention_masks = []\n",
        "        \n",
        "        for tweet in tweets:\n",
        "            encoding_dict = tokenizer('<|sos|>'+ tweet +'<|eos|>',truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length')\n",
        "            \n",
        "            self.input_ids.append(torch.tensor(encoding_dict['input_ids']))\n",
        "            self.attention_masks.append(torch.tensor(encoding_dict['attention_mask']))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.input_ids[idx], self.attention_masks[idx]"
      ],
      "metadata": {
        "id": "zbOZSCSBXdST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#90% training 10% validation\n",
        "\n",
        "dataset = TweetDataset(tweets,tokenizer,max_length=max_tweet)\n",
        "train_size = int(0.90 * len(dataset))\n",
        "val_size = len(dataset)-train_size\n",
        "\n",
        "train,val = random_split(dataset,[train_size,val_size])\n",
        "print(f'Number of train samples = {train_size} and Number of validation samples = {val_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dynk4ZYaXlxA",
        "outputId": "56741efd-52a3-478f-9161-e2d1369f5675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples = 39015 and Number of validation samples = 4336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "# Define dropout probability\n",
        "dropout_prob = 0.081\n",
        "\n",
        "# Add dropout to each layer of the model\n",
        "for layer in model.transformer.h:\n",
        "    layer.dropout = nn.Dropout(dropout_prob)\n",
        "    \n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.cuda()\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "dnQfR2yZYSZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the warmup steps are steps at the start of training that are ignored\n",
        "# every x steps we will sample the model to test the output\n",
        "\n",
        "epochs =10\n",
        "warmup_steps = 1e2\n",
        "sample_every = 100"
      ],
      "metadata": {
        "id": "LeX3gcczYSUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train,sampler = RandomSampler(train),\n",
        "                             batch_size = batch_size)\n",
        "\n",
        "val_dataloader = DataLoader(val,sampler = SequentialSampler(val),\n",
        "                           batch_size = batch_size)"
      ],
      "metadata": {
        "id": "PW1Y8fjnae1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "DIDthgKjZrY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "tbtVkEJWZxy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYvu2hE9hiTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "         "
      ],
      "metadata": {
        "id": "ceaRA1tbiJQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "KbJX4iJFrwF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2O9GfFssaHO",
        "outputId": "e323ab13-be37-4823-e07a-7f04725a5d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 10 19:56:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   5391MiB / 15360MiB |     40%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import os\n",
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    print(f'Beginning epoch {epoch_i + 1} of {epochs}')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        \n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every 100 batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'Batch {step} of {len(train_dataloader)}. Loss:{batch_loss}. Time:{elapsed}')\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1,\n",
        "                                    pad_token_id=tokenizer.eos_token_id\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(f'Example output: {tokenizer.decode(sample_output, skip_special_tokens=True)}')\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids,  \n",
        "                             attention_mask = b_masks,\n",
        "                             labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(f'Validation loss: {avg_val_loss}. Validation Time: {validation_time}')\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f'Total training took {format_time(time.time()-total_t0)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg6fJruud6-d",
        "outputId": "b7f6ffba-07c8-48ec-a539-9ce855196fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning epoch 1 of 10\n",
            "Batch 100 of 1220. Loss:1.8095057010650635. Time:0:01:24\n",
            "Example output:  bipartisan, economic, and security policy alike. President Trump is the best of the best.\n",
            "\n",
            "Batch 200 of 1220. Loss:1.4523214101791382. Time:0:02:49\n",
            "Example output:  increasing.\n",
            "Batch 300 of 1220. Loss:1.5672852993011475. Time:0:04:15\n",
            "Example output: day the\n",
            "Batch 400 of 1220. Loss:1.4591038227081299. Time:0:05:40\n",
            "Example output:  HangWe are working hard to reach an agreement on the deal: Great! (AP) @ FoxNews @washingtonpost/: # TRUMPYOUR_PERMIT_FLOTUS was a success!!!\n",
            "Batch 500 of 1220. Loss:1.5337756872177124. Time:0:07:05\n",
            "Example output:  foods for children\n",
            "Batch 600 of 1220. Loss:1.398107647895813. Time:0:08:29\n",
            "Example output:  trail, to celebrate the 40th anniversary of the landmark building of the historic Columbus, Ohio, Ship Building. The parade was held at the Newseum.    \n",
            "Batch 700 of 1220. Loss:1.6281474828720093. Time:0:09:54\n",
            "Example output: intendJtweet: @ NBCNews, I don't want to see how low will it fall! We need more Fake News!\n",
            "Batch 800 of 1220. Loss:1.1338330507278442. Time:0:11:18\n",
            "Example output:  surround  @ ryancojax: @ realDonaldTrump I would have hated to see you. pic.twitter.com/9cqwvWK3Zg \n",
            "Batch 900 of 1220. Loss:1.4661797285079956. Time:0:12:43\n",
            "Example output:  reflexThis looks like a big one.\n",
            "Batch 1000 of 1220. Loss:1.310587763786316. Time:0:14:09\n",
            "Example output:  display (7 days left)  @ mikefraig @ realDonaldTrump  Will be in NYC, New York in February....  Thank you!\n",
            "Batch 1100 of 1220. Loss:1.3369349241256714. Time:0:15:34\n",
            "Example output:  pastor  @ ChrisTreyBaxter: It looks like my daughter is watching all the Celebrity Apprentice. \n",
            "Batch 1200 of 1220. Loss:1.4134478569030762. Time:0:16:58\n",
            "Example output:  illicit“@ AlexSalmond: “I'm on board. My life will be better soon, tomorrow ” (a major setback)“ @ FoxNews # Trump2016 I don't know how you’t keep your job. I will soon run!\n",
            "Average Training Loss: 1.68056187062967. Epoch time: 0:17:16\n",
            "Validation loss: 1.2086573821656845. Validation Time: 0:00:35\n",
            "Beginning epoch 2 of 10\n",
            "Batch 100 of 1220. Loss:1.349563479423523. Time:0:01:22\n",
            "Example output:  LiberationCatch the latest season of 'Real Time' on @ bbcworld. # LiveAway  @ realtalks \n",
            "Batch 200 of 1220. Loss:1.0550036430358887. Time:0:02:46\n",
            "Example output:  NamA great honor to be on @ FoxNews tomorrow morning at 9:00 AM! …\n",
            "Batch 300 of 1220. Loss:1.238138198852539. Time:0:04:11\n",
            "Example output: IONTired of the constant talk about how the Saudis don't know what Iran is and wants to build a nuclear missile. Is all the talk about sanctions?\n",
            "Batch 400 of 1220. Loss:1.2322496175765991. Time:0:05:35\n",
            "Example output:  glimpseWhy does this guy make such a terrible record on Iran and other nuclear issues, he's one of the least respected and most dangerous\n",
            "Batch 500 of 1220. Loss:1.0783120393753052. Time:0:06:59\n",
            "Example output:  LaureWhen you look at this, you realize that the American people are angry and divided and they're going to change the course of events in Egypt! A mess. They want the results the way that they want. It is all rigged. # Obama2016 \n",
            "Batch 600 of 1220. Loss:1.231460690498352. Time:0:08:23\n",
            "Example output: ism. But not a single Republican or Democrat who believes that the Republican Party of the United States is run by a Democrat has ever held a grudge against a man. The American people have been watching!\n",
            "Batch 700 of 1220. Loss:1.1441220045089722. Time:0:09:47\n",
            "Example output: oun@ Peebofn3r  @ realDonaldTrump What did you do to start out with?\n",
            "Batch 800 of 1220. Loss:1.226936936378479. Time:0:11:11\n",
            "Example output:  election. @ realDonaldTrump needs the Democrats for his nomination. If he doesn't win, we will need a Democrat to run for president.\n",
            "Batch 900 of 1220. Loss:1.1594167947769165. Time:0:12:35\n",
            "Example output:  crazyI agree!pic.twitter.com/5ZHJ4NzwN\n",
            "Batch 1000 of 1220. Loss:1.200629472732544. Time:0:13:59\n",
            "Example output:  bench@ Mr_Nuja3t1 @ realDonaldTrump I'm a big fan of your father. \n",
            "Batch 1100 of 1220. Loss:1.1916424036026. Time:0:15:23\n",
            "Example output:  incorporated....  (cont) \n",
            "Batch 1200 of 1220. Loss:1.2361165285110474. Time:0:16:48\n",
            "Example output: Peter. @ realDonaldTrump I want you to be my President for sure.\n",
            "Average Training Loss: 1.229226038641617. Epoch time: 0:17:06\n",
            "Validation loss: 1.137571748565225. Validation Time: 0:00:35\n",
            "Beginning epoch 3 of 10\n",
            "Batch 100 of 1220. Loss:1.2702394723892212. Time:0:01:22\n",
            "Example output: uring  @ cfriskie1: @ realDonaldTrump if Trump wins I would definitely call him for president & vote for him. He won't let you down!\n",
            "Batch 200 of 1220. Loss:1.2653576135635376. Time:0:02:46\n",
            "Example output:  reproductive  @ bbcmichigan @ CelebApprentice I will be with you every Sunday on @ seanhannity! \n",
            "Batch 300 of 1220. Loss:1.1186485290527344. Time:0:04:10\n",
            "Example output:  zoneBobby Jindal, the self appointed “Governor of Louisiana, has turned his back on @ LouSalmon. He continues to speak and give his personal and political support to the violent thugs who were in Baton Rouge. It is disgusting that he will be forced out.” …\n",
            "Batch 400 of 1220. Loss:1.1751830577850342. Time:0:05:34\n",
            "Example output:  commits. @ realDonaldTrump's top campaign manager, Carly Fiorina, is so badly wounded. # FoxNews  Very weak.\n",
            "Batch 500 of 1220. Loss:1.2286994457244873. Time:0:06:58\n",
            "Example output:  ironyThe Fake News Media can't stop telling me that “there’s no reason why the economy’s at 5.5% and they’re a disaster for the country. The U.S. will crash if we fail to meet our obligations.   Thank you    for doing a great job in this country!\n",
            "Batch 600 of 1220. Loss:1.1053402423858643. Time:0:08:23\n",
            "Example output:  SahThe U.S. is now a nation where there is no longer any military presence to protect against terrorism, no air strikes, and no safe havens and no terrorists. Not a place we have ever met!\n",
            "Batch 700 of 1220. Loss:1.0688791275024414. Time:0:09:48\n",
            "Example output:  BryanCaleb Newman “cont'd” to the Washington Post after receiving death threats\n",
            "Batch 800 of 1220. Loss:1.1874710321426392. Time:0:11:12\n",
            "Example output:  spiritsThe great new book, 'The Art of the Deal': The Art of the Deal by James Baldwin, is available now! Watch this video for a preview! …\n",
            "Batch 900 of 1220. Loss:1.108755350112915. Time:0:12:35\n",
            "Example output:  sees @Mark_Garrett: @ realDonaldTrump @ BarackObama I am a loyal American supporter. We need someone who will respect and respect American citizenship.\n",
            "Batch 1000 of 1220. Loss:0.9656903743743896. Time:0:13:59\n",
            "Example output:  hungryThe Fake News Media has just begun to spin stories that they are losing the election, and they want to keep going after Trump. They say this is because of Crooked Hillary and the DNC.    … … @ mr_chris\n",
            "Batch 1100 of 1220. Loss:1.2919793128967285. Time:0:15:23\n",
            "Example output:  PTPence has spoken, @ BarackObama, about my endorsement of @ MittRomney in NH. He is a tremendous man and has my full and total respect.\n",
            "Batch 1200 of 1220. Loss:0.9980975985527039. Time:0:16:47\n",
            "Example output: ü  @ MrCiclofalbert @ oreillyfactor @ realDonaldTrump please tell all the people that you are a great negotiator to see how the USA is going to be going to the World Cup, I think it could go really fast! You can be the leader and win!\n",
            "Average Training Loss: 1.1601034796140233. Epoch time: 0:17:05\n",
            "Validation loss: 1.1002049533759846. Validation Time: 0:00:35\n",
            "Beginning epoch 4 of 10\n",
            "Batch 100 of 1220. Loss:1.1869494915008545. Time:0:01:22\n",
            "Example output: ruceVia @ foxandfriends: “Donald Trump Is Lying About 'Disgraceful' Meeting With Turkey” …\n",
            "Batch 200 of 1220. Loss:1.2624515295028687. Time:0:02:46\n",
            "Example output:  derivatives  @ cindia_wills: @ realDonaldTrump your the greatest fan of all time I love you!!! @ BarackObama loves you!!!! \n",
            "Batch 300 of 1220. Loss:1.1497381925582886. Time:0:04:10\n",
            "Example output: \u0019“The US should not be at war with Israel. That means putting a damper on their nuclear program!   Israel is a threat to its citizens and it's a threat to us!\n",
            "Batch 400 of 1220. Loss:1.2438162565231323. Time:0:05:34\n",
            "Example output:  remembering@ travox2. Thank you.\n",
            "Batch 500 of 1220. Loss:1.1688365936279297. Time:0:06:57\n",
            "Example output:  Sources. @ BarackObama has done more than just a great job. What we need now is for him to do much more in life.\n",
            "Batch 600 of 1220. Loss:1.2994335889816284. Time:0:08:21\n",
            "Example output: emsSo I've given a speech tonight in D.C. (which was good), where I discuss the ridiculous attack, terrorism, and other things that the Dems, at some point, might choose to do on their own!\n",
            "Batch 700 of 1220. Loss:1.1845518350601196. Time:0:09:46\n",
            "Example output: tzI just won, I won’t be taking my new campaign seriously!\n",
            "Batch 800 of 1220. Loss:1.0292006731033325. Time:0:11:10\n",
            "Example output: matic  @ Jhannap: @ realDonaldTrump you should run because they are winning! \n",
            "Batch 900 of 1220. Loss:0.9326742887496948. Time:0:12:35\n",
            "Example output:  syndThe Fake News Media has done a GREAT job! pic.twitter.com/fv4ZxgOj6E\n",
            "Batch 1000 of 1220. Loss:1.1233162879943848. Time:0:14:00\n",
            "Example output:  gamThe @ CNNDebate tonight on @ CNNPolitics is just as biased and inaccurate as the real election results. It is all the rage!\n",
            "Batch 1100 of 1220. Loss:1.099814772605896. Time:0:15:24\n",
            "Example output:  injuryThe Democrat primary has failed to provide any real political solution. If Republicans want to win their primaries, they must immediately go back to being politically correct.\n",
            "Batch 1200 of 1220. Loss:0.9862222671508789. Time:0:16:47\n",
            "Example output: azaThe Chinese are taking a beating. China is taking over North Korea. \n",
            "Average Training Loss: 1.115551807352754. Epoch time: 0:17:05\n",
            "Validation loss: 1.0767375274616129. Validation Time: 0:00:35\n",
            "Beginning epoch 5 of 10\n",
            "Batch 100 of 1220. Loss:1.1568076610565186. Time:0:01:22\n",
            "Example output:  membrane  @ pfranza: @ realDonaldTrump please run the country!! @ BarackObama needs to run! If you are elected president, we will run to give our Country back to you!!\n",
            "Batch 200 of 1220. Loss:0.9346421360969543. Time:0:02:48\n",
            "Example output: ijing“We must not let go of what makes a person a person. We must respect a person.” – Think Like A Champion\n",
            "Batch 300 of 1220. Loss:1.0219554901123047. Time:0:04:12\n",
            "Example output:  castIt was my great honor to visit the Southern Border last night, at the National Border Patrol Council. We were honored to have a meeting with Border Patrol Officers of the Administration, ICE, and many others. Great energy. pic.twitter.com/jW4Ep6Fv7PJ\n",
            "Batch 400 of 1220. Loss:1.08368980884552. Time:0:05:36\n",
            "Example output:  purchThe American people deserve a winner, the American worker has the right to choose and, in so doing, create a better economy and work more efficiently for their families. This cannot happen without the rule of law. The Federal Reserve & the Fed are fully aware of that, we cannot allow President Trump to give orders that his deputies won't. There is no Collusion between the two.\n",
            "Batch 500 of 1220. Loss:0.911492109298706. Time:0:07:00\n",
            "Example output:  shouldersMy @ CNN interview discussing # Trump2016.pic.twitter.com/nK0Tgf9kXk\n",
            "Batch 600 of 1220. Loss:1.0889233350753784. Time:0:08:24\n",
            "Example output:  builtI have written many books on the subject. I don't see how a book about a president can be so politically incorrect. He can easily be wrong on almost every area of government and in every category. The Democrats should fire him.\n",
            "Batch 700 of 1220. Loss:1.1098194122314453. Time:0:09:48\n",
            "Example output:  openly“They've taken away a great business opportunity!” @ SteveHilton\n",
            "Batch 800 of 1220. Loss:1.0468130111694336. Time:0:11:12\n",
            "Example output:  haltedI am having dinner with Ukrainian President Petro Poroshenko   you can see his massive military machine guns, and I would love him to keep them away from our troops. They are so heavy they can hurt & kill the Ukrainian People!\n",
            "Batch 900 of 1220. Loss:0.9947879910469055. Time:0:12:36\n",
            "Example output:  Nik  @ CUTCRACK0RE: I'll bet my $$$ (in Trump International Golf Club) with a hole made in the top of a course in Scotland will be a winner. \n",
            "Batch 1000 of 1220. Loss:1.0775476694107056. Time:0:14:00\n",
            "Example output:  tin  @ tchobekker: @ realDonaldTrump The next president you run is my favorite man!!  Thank you!\n",
            "Batch 1100 of 1220. Loss:0.8190178275108337. Time:0:15:25\n",
            "Example output:  clinical@ @ dpbohlef Thanks.\n",
            "Batch 1200 of 1220. Loss:1.1223706007003784. Time:0:16:49\n",
            "Example output: lections. @ BarackObama wants your tax dollars, not your workers!\n",
            "Average Training Loss: 1.0803779885417126. Epoch time: 0:17:07\n",
            "Validation loss: 1.0607159689945334. Validation Time: 0:00:35\n",
            "Beginning epoch 6 of 10\n",
            "Batch 100 of 1220. Loss:1.0385993719100952. Time:0:01:22\n",
            "Example output: elsSo happy that @ kylehannity just said I will be on the @ greta show tonight at 7 PM EST. Thank you!\n",
            "Batch 200 of 1220. Loss:1.1841011047363281. Time:0:02:47\n",
            "Example output: lab  @ seanhardieg: @ realDonaldTrump I'm going to vote for you next year I'm so excited! \n",
            "Batch 300 of 1220. Loss:1.1430240869522095. Time:0:04:11\n",
            "Example output:  triple. @ NBCPolitics is doing great reporting on the # ImWithYou events. Much like CNN CNN, the ratings are way down the road  A record.\n",
            "Batch 400 of 1220. Loss:1.0391106605529785. Time:0:05:35\n",
            "Example output: 220  @ lisangelic101: @ realDonaldTrump @ DontGetJobs Trump is making life so easy for a rich person. \n",
            "Batch 500 of 1220. Loss:0.930855929851532. Time:0:06:59\n",
            "Example output:  See. @ jaketapper made a fortune with @ Macys. He should be fired! # CelebApprentice\n",
            "Batch 600 of 1220. Loss:0.9364034533500671. Time:0:08:23\n",
            "Example output: @@ @jodeljames: @ realDonaldTrump The only real chance you have to run was last time you were president. @ greta is a complete disgrace. \n",
            "Batch 700 of 1220. Loss:1.162972331047058. Time:0:09:47\n",
            "Example output:  host  @ jon_le: @ realDonaldTrump you should win this race. You make me proud by doing what nobody else can. # CelebApprentice \n",
            "Batch 800 of 1220. Loss:1.0567235946655273. Time:0:11:11\n",
            "Example output: role  @ jimmyj_sarah: @ realDonaldTrump @ realDonaldTrump your so smart Mr.Trump!!  Great, thanks.\n",
            "Batch 900 of 1220. Loss:1.1134299039840698. Time:0:12:36\n",
            "Example output: iac....   @ jennifermcuban and the phony and corrupt media  never knew what they were doing. # Trump2016\n",
            "Batch 1000 of 1220. Loss:1.0506985187530518. Time:0:14:01\n",
            "Example output:  LDOur country's debt at a record high is not acceptable to anyone   but will explode!\n",
            "Batch 1100 of 1220. Loss:1.0291526317596436. Time:0:15:25\n",
            "Example output:  ListenWhen people in Washington, DC are being lied to by the Democrats, who have done nothing to stop the death spiral they are in and what the hell is going on and are in the White House doing. If President Obama is going to act in this way, he should not be on TV telling them this was a Witch Hunt in disguise!\n",
            "Batch 1200 of 1220. Loss:1.0330767631530762. Time:0:16:50\n",
            "Example output:  dyWow! @ FoxNews @ SenTedCruz, who has no idea the truth is out, has no clue how to answer the biggest questions in my life \n",
            "Average Training Loss: 1.049576538214918. Epoch time: 0:17:08\n",
            "Validation loss: 1.049573830821935. Validation Time: 0:00:35\n",
            "Beginning epoch 7 of 10\n",
            "Batch 100 of 1220. Loss:1.1284657716751099. Time:0:01:22\n",
            "Example output:  DomesticThe people in our Country are having to fight each day to get what they want, but the Democrats have no interest in it, & they are far more concerned about protecting those who get the bill out of Congress.\n",
            "Batch 200 of 1220. Loss:1.0480273962020874. Time:0:02:46\n",
            "Example output:  beneficiaries  @ kyler11: @ realDonaldTrump @ ApprenticeNBC @ TrumpChicago @ realDonaldTrump will u run to the top in your office in 5 years  So true!\n",
            "Batch 300 of 1220. Loss:0.8411526679992676. Time:0:04:10\n",
            "Example output:  Title  @ kcgneiss: @ realDonaldTrump @ greta   America needs a patriot like you, we need one!!  Thank you.\n",
            "Batch 400 of 1220. Loss:0.9413634538650513. Time:0:05:34\n",
            "Example output:  μ  @ MJPADOWSK: @ realDonaldTrump why have you been in trouble in the UK? I never left so much as a blank! \n",
            "Batch 500 of 1220. Loss:0.9932500123977661. Time:0:06:58\n",
            "Example output:  sellingIt's no secret that @ CNN, @ seanhannity & @ TheView are among the Fake News Networks. # Do ItRight\n",
            "Batch 600 of 1220. Loss:1.0546444654464722. Time:0:08:22\n",
            "Example output:  migrantWe will build the best roads & bridges anywhere in the world & build a wall between the two nations that are NOT allowing us to. A Wall will end and nobody will ever have a chance. We will keep moving forward to Make America Great Again!\n",
            "Batch 700 of 1220. Loss:0.9825317859649658. Time:0:09:47\n",
            "Example output: ively  @ b_chrysler: @ realDonaldTrump @ IvankaTrump is one of the few real talent to have the brains of a president who is going to deliver on the promise made to him by his father \n",
            "Batch 800 of 1220. Loss:1.0002394914627075. Time:0:11:12\n",
            "Example output:  order@ karl_w_singer  Thank you.\n",
            "Batch 900 of 1220. Loss:1.2019375562667847. Time:0:12:36\n",
            "Example output:  VPN@ piersmorgan Great  thanks for the nice words.\n",
            "Batch 1000 of 1220. Loss:1.0592540502548218. Time:0:14:00\n",
            "Example output:  explanation  @ Tzwiler: @ realDonaldTrump the new @ gretawire is great!\n",
            "Batch 1100 of 1220. Loss:1.0284820795059204. Time:0:15:24\n",
            "Example output:  BachVia @ thehill: “Trump Calls GOP Poll 'Sugar Bowl'” …\n",
            "Batch 1200 of 1220. Loss:0.996368408203125. Time:0:16:48\n",
            "Example output:  folder@ jeff_bush Thank you.\n",
            "Average Training Loss: 1.0221508117972828. Epoch time: 0:17:05\n",
            "Validation loss: 1.0414411592132904. Validation Time: 0:00:35\n",
            "Beginning epoch 8 of 10\n",
            "Batch 100 of 1220. Loss:1.0008176565170288. Time:0:01:22\n",
            "Example output:  building....or it will fall apart. The Obama Administration should stop talking about how badly they are doing to build, renovate, and manage the massive, failing Federal Waste Management System (FWS) and other critical infrastructure.” @ seanhannity @ washingtonpost It will be all right  so true!\n",
            "Batch 200 of 1220. Loss:0.9900770783424377. Time:0:02:46\n",
            "Example output:  Babylon“The Mueller Report has given him no evidence or analysis of the crime committed and the crimes committed.” John Sununu. They have zero evidence of collusion with Russia. Fake News Media is a laughing stock of our Country and is working overtime for the Dems, the same as never before!\n",
            "Batch 300 of 1220. Loss:1.0630744695663452. Time:0:04:10\n",
            "Example output: perial@ davefitzman True!\n",
            "Batch 400 of 1220. Loss:1.1082228422164917. Time:0:05:34\n",
            "Example output:  rents  @ J_Lucex: I know you're right about Obama. We need someone who isn't too passive, who can stay focused & get results. @ realDonaldTrump \n",
            "Batch 500 of 1220. Loss:1.042248010635376. Time:0:06:58\n",
            "Example output:  Reg....I want to bring our nation back to a healthy and prosperous future. We can make our Country stronger by making America Great Again. We have my Complete Endorsement!pic.twitter.com/KL7VxRQ5pI\n",
            "Batch 600 of 1220. Loss:0.9206783175468445. Time:0:08:22\n",
            "Example output: olas  @ RealKJ_: @ realDonaldTrump If you would only be the one to make that announcement..please run for president! \n",
            "Batch 700 of 1220. Loss:0.9969568252563477. Time:0:09:46\n",
            "Example output:  responses  @ realyammer: @ DanAmira @ foxandfriends Don't know the answer to that. \n",
            "Batch 800 of 1220. Loss:1.0012956857681274. Time:0:11:10\n",
            "Example output:  attendance  @ _jenna_lechtner: We need @ realDonaldTrump to lead us in the race. He has my vote \n",
            "Batch 900 of 1220. Loss:0.9305674433708191. Time:0:12:35\n",
            "Example output:  rigid  @ ludloyd @ MikeAndMike I agree. I was watching you on # CelebrityApprentice but you were GREAT. \n",
            "Batch 1000 of 1220. Loss:1.0292532444000244. Time:0:14:00\n",
            "Example output: gro. @ BarackObama is now saying, “If you want to be America’s leader, you have to be ready to lead.” So what? Where are the leaders who lead?\n",
            "Batch 1100 of 1220. Loss:0.8227951526641846. Time:0:15:25\n",
            "Example output:  Gre  @ The_Joe_: @ realDonaldTrump I can see why people would want to hear this now! # trump2016 \n",
            "Batch 1200 of 1220. Loss:1.0367528200149536. Time:0:16:48\n",
            "Example output: uraOur Country Needs A Republican. They want a President who will protect the Second Amendment, promote American HealthCare, and get our jobs back   and that is what we need in November!\n",
            "Average Training Loss: 0.9980459051054033. Epoch time: 0:17:06\n",
            "Validation loss: 1.0342072406235863. Validation Time: 0:00:35\n",
            "Beginning epoch 9 of 10\n",
            "Batch 100 of 1220. Loss:0.9348179697990417. Time:0:01:22\n",
            "Example output:  2020  @ JE_Barry19: @ realDonaldTrump The U.S. needs Trump to Make the world a better place.  True, so!\n",
            "Batch 200 of 1220. Loss:0.9838049411773682. Time:0:02:47\n",
            "Example output:  charging  @ cgordon75: @ realDonaldTrump @ krauthammer @ seanhannity why dont u run? \n",
            "Batch 300 of 1220. Loss:1.0674586296081543. Time:0:04:11\n",
            "Example output:  Sar  @ jefftacson: I've never seen anyone as strong as the Donald. That guy is unstoppable! \n",
            "Batch 400 of 1220. Loss:0.8871551156044006. Time:0:05:36\n",
            "Example output:  JasSo many polls today. Thank you to all, I love working with you!\n",
            "Batch 500 of 1220. Loss:0.9117742776870728. Time:0:06:59\n",
            "Example output:  permitThank you for our good wishes! …\n",
            "Batch 600 of 1220. Loss:1.0015143156051636. Time:0:08:23\n",
            "Example output:  Administrator  @ mikah__m: @ realDonaldTrump @ CSPAN1 @ DanScavino Very Interesting!  Thank you!\n",
            "Batch 700 of 1220. Loss:0.9333927035331726. Time:0:09:47\n",
            "Example output:  EVENTSThe U.S. Embassy in Kenya was stormed on June 16, 2017. We will forever cherish it and protect it!\n",
            "Batch 800 of 1220. Loss:1.002766728401184. Time:0:11:11\n",
            "Example output:  Mental“This is a president who doesn’t want to waste time trying to defend the Republican nominee,” said Bruce Ohr, a retired U.S. Army\n",
            "Batch 900 of 1220. Loss:0.9937071204185486. Time:0:12:36\n",
            "Example output: idsEntrepreneurs: Never underestimate yourself. Don't tread water  you'll learn a thing or two from others.\n",
            "Batch 1000 of 1220. Loss:0.9018572568893433. Time:0:14:01\n",
            "Example output: ceansCongratulations to @ FoxNews for winning the @ TimeToGetTough debate!\n",
            "Batch 1100 of 1220. Loss:1.0143086910247803. Time:0:15:26\n",
            "Example output:  genetically @RealTyrone829: @ realDonaldTrump can't wait to see you on @ TheApprentice @ ApprenticeNBC tonight, # CelebApprentice!!! \n",
            "Batch 1200 of 1220. Loss:1.0804163217544556. Time:0:16:50\n",
            "Example output:  advice  @ davewebb: @ realDonaldTrump Your mother is awesome...she really gets it! \n",
            "Average Training Loss: 0.9756973241684866. Epoch time: 0:17:08\n",
            "Validation loss: 1.030433986993397. Validation Time: 0:00:35\n",
            "Beginning epoch 10 of 10\n",
            "Batch 100 of 1220. Loss:1.0176986455917358. Time:0:01:22\n",
            "Example output:  incomplete  @ RealMattD_: @ realDonaldTrump @ lancearmstrong i love you so much, but i think the @ greta doesn't understand how hard it is to keep America together...so hard and so dumb  Thanks Matt.\n",
            "Batch 200 of 1220. Loss:0.8497750759124756. Time:0:02:46\n",
            "Example output: comment@ dasdevil1 Hi Sir.\n",
            "Batch 300 of 1220. Loss:0.8557870984077454. Time:0:04:10\n",
            "Example output:  pilot  @ fattakeel: @ realDonaldTrump what's your best advice for the kids in Chicago?  I want to learn how to be an entrepreneur.\n",
            "Batch 400 of 1220. Loss:0.96892911195755. Time:0:05:35\n",
            "Example output: gersThank you! # AmericaFirstpic.twitter.com/6F6zY7uR1R\n",
            "Batch 500 of 1220. Loss:1.028802752494812. Time:0:06:59\n",
            "Example output:  mutation  @ DollyDollyDolly: @ realDonaldTrump I love the interview with @ realDonaldTrump who just ran a great business! \n",
            "Batch 600 of 1220. Loss:0.9311189651489258. Time:0:08:23\n",
            "Example output:  DriverSo sad when @ BarackObama promised that he is going to raise interest rates by 2% at the end of the year and when he actually did raise the rate!\n",
            "Batch 700 of 1220. Loss:0.9707454442977905. Time:0:09:48\n",
            "Example output: itiGreat @ ApprenticeNBC interview, I think the viewers will love them!\n",
            "Batch 800 of 1220. Loss:0.9029366970062256. Time:0:11:12\n",
            "Example output: fff @DowdyJedi: @ realDonaldTrump Run for president, we need you. You are my inspiration  Thanks.\n",
            "Batch 900 of 1220. Loss:0.8715488910675049. Time:0:12:36\n",
            "Example output: rimination...have not been broken. The FBI, ICE & DOD must do everything possible to get the Radical Left Democrat President to release the Transcripts and all other documents so that the American people can see for themselves what was said and how he came to believe it!\n",
            "Batch 1000 of 1220. Loss:0.9286845922470093. Time:0:14:00\n",
            "Example output: aque  @ mrs_laura: @ realDonaldTrump is making America great again. So many good ideas about America  Thanks!\n",
            "Batch 1100 of 1220. Loss:0.9517587423324585. Time:0:15:24\n",
            "Example output: lee  @ jimmybob: @ realDonaldTrump  Thank you Mr Trump for sharing your love of Americana   # Trump2016 # Trump2016 \n",
            "Batch 1200 of 1220. Loss:0.986298680305481. Time:0:16:49\n",
            "Example output:  Alzheimer@ dennishawkins Thanks Dennis.\n",
            "Average Training Loss: 0.9550148057644484. Epoch time: 0:17:07\n",
            "Validation loss: 1.025224328479346. Validation Time: 0:00:35\n",
            "Total training took 2:57:04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('precision', 10)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "xt = [i for i in range(1,epochs+1)]\n",
        "plt.xticks(xt)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hDuGXgLvxnvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "2dffc2fd-9edd-4f22-90df-1b039fd21deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "out_dir = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained('./')\n",
        "tokenizer.save_pretrained('./')\n",
        "model_to_save.save_pretrained(out_dir)\n",
        "tokenizer.save_pretrained(out_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "ywdV3fa9JYpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c411bf-1d79-4b2c-c0d1-5c4b8b7609c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/vocab.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/merges.txt',\n",
              " '/content/drive/MyDrive/Colab Notebooks/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "prompt = \"<|sos|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "YWykmxtr45xN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df101fc1-86e0-4330-c89a-1e187ee11795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Why is @ BarackObama allowing @ MittRomney to fundraise after raising more than $5 million for charity & paying Obama's campaign nearly $50M?\n",
            "\n",
            "\n",
            "1: pic.twitter.com/xoWkOv3oEq\n",
            "\n",
            "\n",
            "2:  @LemmyJoni @ realDonaldTrump Donald you are the man! You can make this country great again! Thank you!  Thanks.\n",
            "\n",
            "\n",
            "3: Why doesn't the Democrats do a full & complete investigation, that will lead to the arrest of Crooked Hillary Clinton   as though the Dems knew there was such a big problem!\n",
            "\n",
            "\n",
            "4: # TrumpVine The Best # PollingVine # GOPDebatepic.twitter.com/v2U5F8j8K8\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Saved Model\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('./')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('./')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ibC8lgLZZ2F5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a4d386-c676-434a-deef-2c0e2963ad2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50260, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_2012 = 'this is crazy  '\n",
        "model.eval()\n",
        "\n",
        "prompt = tweet_2012\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 250,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, outputs in enumerate(outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(outputs, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "AfQ9lAYgDoFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa28baac-ef8a-42dd-c4ae-205ad7fec0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: this is crazy    @ billmaher has $700M to show up at the @ nytimes in his first two years. # trump \n",
            "\n",
            "\n",
            "1: this is crazy   this is happening   and our country is in a financial mess. @ BarackObama is a weak & ineffective leader.\n",
            "\n",
            "\n",
            "2: this is crazy   but the media is trying hard   they just aren't as sharp & unbiased as we used to be. \n",
            "\n",
            "\n",
            "3: this is crazy   @ AlexSalmond says Scotland will be taxed up to £300 a month.\n",
            "\n",
            "\n",
            "4: this is crazy   the number of illegal immigrants that the Border Patrol Agents are getting is far higher than the total number of the illegal immigrants who have committed crimes, including murder   and that is a total FAKE NEWS story. I have been doing this for many years, and if they are afraid to report it, I will report it anyway. Not good. The Wall is being built!\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "import pickle\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/finalized_model10E.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "J1Vcs839amzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U08pU9Vjbk_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FJO_ntza2Nj",
        "outputId": "09c97aff-bf83-4d15-f380-65fd7fc699d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50260, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}